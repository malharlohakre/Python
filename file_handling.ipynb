{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b2f6b35-aec8-408f-9601-3db0d57e967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = read\n",
    "# w = write (create a new file)\n",
    "# a = append\n",
    "# x = create a new file\n",
    "# rb = read binary\n",
    "# wb = write binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57ed9f9-fa73-4143-ad3a-97b27e32e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  w = write (create a new file)\n",
    "file = open('cwpc.txt','w')\n",
    "file.write('welcome to python learning hub\\n')\n",
    "file.write('welcome to python learning hub part 1\\n')\n",
    "file.write('welcome to python learning hub part 2\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb4750d-5202-4625-9bdb-9693c80de647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome to python learning hub\n",
      "welcome to python learning hub part 1\n",
      "welcome to python learning hub part 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# r- read \n",
    "file = open('cwpc.txt','r')\n",
    "data = file.read()\n",
    "print(data)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed4464ee-1465-4d97-86c9-0bdbe6f47f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome to python learning hub\\n', 'welcome to python learning hub part 1\\n', 'welcome to python learning hub part 2\\n']\n"
     ]
    }
   ],
   "source": [
    "# read line list[]\n",
    "file = open(\"cwpc.txt\",\"r\")\n",
    "data = file.readlines()\n",
    "print(data)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95cb00f-75e4-4627-86b0-8be9aed7f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append data into file\n",
    "file = open(\"cwpc.txt\",\"a\")\n",
    "file.write(\"\\n new data line append\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2beb9f-351f-4336-8d9c-f8f47be7e608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome to python learning hub\n",
      "welcome to python learning hub part 1\n",
      "welcome to python learning hub part 2\n",
      "\n",
      " new data line append\n"
     ]
    }
   ],
   "source": [
    "# best method\n",
    "with open (\"cwpc.txt\",\"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9edf085d-58c0-462c-bf1e-f5bef22221a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome to python learning hub\n",
      "welcome to python learning hub part 1\n",
      "welcome to python learning hub part 2\n",
      "\n",
      "new data line append\n"
     ]
    }
   ],
   "source": [
    "# file with loop \n",
    "with open (\"cwpc.txt\",'r') as file:\n",
    "    for i in file:\n",
    "        print(i.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17132e0b-d764-45af-b298-b5774bc7b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"cwpc.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f630b3bc-bcb9-4b18-a23f-cd24475498cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with image file\n",
    "with open (\"img.jpg\",\"rb\") as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2834bb30-d95e-4591-9d27-d20901055e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy img file\n",
    "with open (\"copy.img\",'wb') as target:\n",
    "    target.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349aa37-3113-430c-b58f-18929d1fb302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pillow pkg for read image from folder\n",
    "# pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "650deede-8b9f-4dfb-a92c-3e4d311e0cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "# read pdf file using pypdf2\n",
    "#install pkg\n",
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46d419dc-1862-4f96-8612-ec883bb836e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total page -  5\n",
      "\n",
      "---page--1---\n",
      "\n",
      "Building a Decision Tree from Scratch with ID3\n",
      "Algorithm\n",
      "August 28, 2025\n",
      "1 Introduction\n",
      "Decision trees are a powerful machine learning tool used for classiﬁcation and regres-\n",
      "sion tasks, representing decisions in a ﬂowchart-like structure. This tutorial provides a\n",
      "comprehensive guide to building a decision tree using the ID3 (Iterative Dichotomiser 3)\n",
      "algorithm, focusing on classiﬁcation. We’ll use the “Play Tennis” dataset to demonstrate\n",
      "the process, including calculations for Entropy and Information Gain, and show how to\n",
      "construct and use the tree for predictions. This guide is beginner-friendly yet detailed,\n",
      "with a complete example dataset.\n",
      "2 Why Decision Trees?\n",
      "Decision trees are popular because:\n",
      "•They are intuitive and easy to visualize.\n",
      "•They handle both categorical and numerical data.\n",
      "•No data normalization is required.\n",
      "•They capture non-linear relationships.\n",
      "Applications include spam detection, customer churn prediction, and medical diagnosis.\n",
      "We’ll use the ID3 algorithm, which selects splits based on Information Gain.\n",
      "3 Key Concepts\n",
      "3.1 Entropy\n",
      "Entropy measures the impurity or uncertainty in a dataset. For a binary classiﬁcation\n",
      "(e.g., Yes/No), it is calculated as:\n",
      "S=−c∑\n",
      "i=1pilog2pi\n",
      "where cis the number of classes, and piis the proportion of examples in class i. A lower\n",
      "entropy indicates a purer dataset (e.g., all examples in one class: S= 0).\n",
      "1\n",
      "\n",
      "---page--2---\n",
      "\n",
      "3.2 Information Gain\n",
      "Information Gain (IG) measures how much entropy is reduced by splitting on an attribute:\n",
      "IG(A) =Sparent−∑\n",
      "v∈values (A)|Dv|\n",
      "|D|Sv\n",
      "where Ais the attribute, Dvis the subset for value v, and |D|is the total dataset size.\n",
      "ID3 selects the attribute with the highest IG for each node.\n",
      "4 Example Dataset: Play Tennis\n",
      "We’ll use the “Play Tennis” dataset to decide whether to play tennis based on weather\n",
      "conditions. It has 14 instances and 4 attributes, plus the target class (Play Tennis: Yes\n",
      "or No).\n",
      "Table 1: Play Tennis Dataset\n",
      "Day Outlook Temperature Humidity Wind Play Tennis\n",
      "1 Sunny Hot High Weak No\n",
      "2 Sunny Hot High Strong No\n",
      "3 Overcast Hot High Weak Yes\n",
      "4 Rain Mild High Weak Yes\n",
      "5 Rain Cool Normal Weak Yes\n",
      "6 Rain Cool Normal Strong No\n",
      "7 Overcast Cool Normal Strong Yes\n",
      "8 Sunny Mild High Weak No\n",
      "9 Sunny Cool Normal Weak Yes\n",
      "10 Rain Mild Normal Weak Yes\n",
      "11 Sunny Mild Normal Strong Yes\n",
      "12 Overcast Mild High Strong Yes\n",
      "13 Overcast Hot Normal Weak Yes\n",
      "14 Rain Mild High Strong No\n",
      "Attributes:\n",
      "•Outlook : Sunny, Overcast, Rain\n",
      "•Temperature : Hot, Mild, Cool\n",
      "•Humidity : High, Normal\n",
      "•Wind : Weak, Strong\n",
      "•Target : Play Tennis (9 Yes, 5 No)\n",
      "2\n",
      "\n",
      "---page--3---\n",
      "\n",
      "5 Step-by-Step: Building the Decision Tree\n",
      "5.1 Step 1: Entropy of the Entire Dataset\n",
      "Total instances: 14 (9 Yes, 5 No).\n",
      "pYes=9\n",
      "14, p No=5\n",
      "14\n",
      "S=−(9\n",
      "14log29\n",
      "14+5\n",
      "14log25\n",
      "14)\n",
      "≈0.940\n",
      "5.2 Step 2: Information Gain for Each Attribute\n",
      "We compute IG for Outlook, Temperature, Humidity, and Wind.\n",
      "5.2.1 Outlook\n",
      "Values: Sunny (5: 2 Yes, 3 No), Overcast (4: 4 Yes, 0 No), Rain (5: 3 Yes, 2 No).\n",
      "Entropy for Sunny:\n",
      "SSunny =−(2\n",
      "5log22\n",
      "5+3\n",
      "5log23\n",
      "5)\n",
      "≈0.971\n",
      "Entropy for Overcast:\n",
      "SOvercast =−(4\n",
      "4log24\n",
      "4+0\n",
      "4log20\n",
      "4)\n",
      "= 0\n",
      "Entropy for Rain:\n",
      "SRain=−(3\n",
      "5log23\n",
      "5+2\n",
      "5log22\n",
      "5)\n",
      "≈0.971\n",
      "IGOutlook = 0.940−(5\n",
      "14×0.971 +4\n",
      "14×0 +5\n",
      "14×0.971)\n",
      "≈0.247\n",
      "5.2.2 Temperature\n",
      "Values: Hot (4: 2 Yes, 2 No), Mild (6: 4 Yes, 2 No), Cool (4: 3 Yes, 1 No). Entropies:\n",
      "Hot≈1.000, Mild ≈0.918, Cool ≈0.811.\n",
      "IGTemp = 0.940−(4\n",
      "14×1.000 +6\n",
      "14×0.918 +4\n",
      "14×0.811)\n",
      "≈0.029\n",
      "5.2.3 Humidity\n",
      "Values: High (7: 3 Yes, 4 No), Normal (7: 6 Yes, 1 No). Entropies: High ≈0.985, Normal\n",
      "≈0.592.\n",
      "IGHumidity = 0.940−(7\n",
      "14×0.985 +7\n",
      "14×0.592)\n",
      "≈0.151\n",
      "5.2.4 Wind\n",
      "Values: Weak (8: 6 Yes, 2 No), Strong (6: 3 Yes, 3 No). Entropies: Weak ≈0.811,\n",
      "Strong ≈1.000.\n",
      "IGWind = 0.940−(8\n",
      "14×0.811 +6\n",
      "14×1.000)\n",
      "≈0.048\n",
      "Highest IG : Outlook (0.247) →Root node.\n",
      "3\n",
      "\n",
      "---page--4---\n",
      "\n",
      "5.3 Step 3: Split and Recurse\n",
      "•Overcast : All 4 Yes →Leaf node: Yes.\n",
      "•Sunny (5 instances, entropy 0.971): Highest IG is Humidity (1.000).\n",
      "–High (3: 0 Yes, 3 No) →Leaf: No.\n",
      "–Normal (2: 2 Yes, 0 No) →Leaf: Yes.\n",
      "•Rain (5 instances, entropy 0.971): Highest IG is Wind (0.971).\n",
      "–Weak (3: 3 Yes, 0 No) →Leaf: Yes.\n",
      "–Strong (2: 0 Yes, 2 No) →Leaf: No.\n",
      "5.4 Step 4: Final Decision Tree\n",
      "Outlook\n",
      "/| \\\n",
      "Sunny Overcast Rain\n",
      "| | |\n",
      "Humidity Yes Wind\n",
      "/\\ /\\\n",
      "High Normal Weak Strong\n",
      "No Yes Yes No\n",
      "6 Making Predictions\n",
      "For a new instance (Sunny, Mild, High, Strong):\n",
      "•Outlook = Sunny →Humidity.\n",
      "•Humidity = High →No (Don’t play).\n",
      "For Rain, Cool, Normal, Weak:\n",
      "•Outlook = Rain →Wind.\n",
      "•Wind = Weak →Yes (Play).\n",
      "7 Python Implementation\n",
      "Here’s a Python script using scikit-learn to automate the process:\n",
      "from sklearn import tree\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "# Load dataset\n",
      "data = pd.DataFrame({\n",
      "’Outlook’: [’Sunny’, ’Sunny’, ’Overcast’, ’Rain’, ’Rain’, ’Rain’, ’Overcast’,\n",
      "4\n",
      "\n",
      "---page--5---\n",
      "\n",
      "’Sunny’, ’Sunny’, ’Rain’, ’Sunny’, ’Overcast’, ’Overcast’, ’Rain’],\n",
      "’Temperature’: [’Hot’, ’Hot’, ’Hot’, ’Mild’, ’Cool’, ’Cool’, ’Cool’, ’Mild’,\n",
      "’Cool’, ’Mild’, ’Mild’, ’Mild’, ’Hot’, ’Mild’],\n",
      "’Humidity’: [’High’, ’High’, ’High’, ’High’, ’Normal’, ’Normal’, ’Normal’,\n",
      "’High’, ’Normal’, ’Normal’, ’Normal’, ’High’, ’Normal’, ’High’],\n",
      "’Wind’: [’Weak’, ’Strong’, ’Weak’, ’Weak’, ’Weak’, ’Strong’, ’Strong’, ’Weak’,\n",
      "’Weak’, ’Weak’, ’Strong’, ’Strong’, ’Weak’, ’Strong’],\n",
      "’Play’: [’No’, ’No’, ’Yes’, ’Yes’, ’Yes’, ’No’, ’Yes’, ’No’, ’Yes’, ’Yes’,\n",
      "’Yes’, ’Yes’, ’Yes’, ’No’]\n",
      "})\n",
      "# Encode categorical data\n",
      "le = LabelEncoder()\n",
      "for col in data.columns:\n",
      "data[col] = le.fit_transform(data[col])\n",
      "X = data.drop(’Play’, axis=1)\n",
      "y = data[’Play’]\n",
      "# Train decision tree\n",
      "clf = tree.DecisionTreeClassifier(criterion=’entropy’)\n",
      "clf.fit(X, y)\n",
      "8 Limitations and Tips\n",
      "•Overﬁtting : Prune trees or use ensembles like Random Forests.\n",
      "•Bias : ID3 favors attributes with many values.\n",
      "•Continuous Data : Use C4.5 or CART for numerical data.\n",
      "•Tip: Use a calculator for entropy calculations.\n",
      "9 Conclusion\n",
      "This tutorial demonstrated how to build a decision tree using the ID3 algorithm with the\n",
      "Play Tennis dataset. By calculating Entropy and Information Gain, we constructed a\n",
      "tree to predict whether to play tennis. Practice with new datasets, explore libraries like\n",
      "scikit-learn, or dive into Random Forests for advanced learning.\n",
      "For more AI resources, visit x.ai. Happy learning!\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2 as pd\n",
    "\n",
    "with open(\"data.pdf\",\"rb\") as file:\n",
    "    reader = pd.PdfReader(file)\n",
    "    \n",
    "    # get total number of page \n",
    "    print(\"total page - \",len(reader.pages))\n",
    "    page_size = len(reader.pages)\n",
    "\n",
    "    # read text from each page \n",
    "    for i in range(page_size):\n",
    "        page = reader.pages[i]\n",
    "        text = page.extract_text()\n",
    "        print(f\"\\n---page--{i+1}---\\n\")\n",
    "        print(text)\n",
    "\n",
    "    # single page data\n",
    "    # page = reader.pages[2]\n",
    "    # text = page.extract_text()\n",
    "    # print(text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccf657-5f96-40f8-9ef0-a63b54b1a2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
